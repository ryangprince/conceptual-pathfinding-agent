{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7152950e",
   "metadata": {},
   "source": [
    "## Self-Reflective Research (Research Crew)\n",
    "\n",
    "Research Scout (Agent): Generates highly specific search queries based on the Mapper Agent's key entities and flagged claims.\n",
    "* Output structure: Initial raw search results (Snippets, URLs).\n",
    "\n",
    "Critique Agent: Reads the raw results, identifies contradictions, missing sources, or lack of factual support for the claims identified in Stage 1 (Mapper Agent).\n",
    "* Output structure: \n",
    "    * **Critique Report**: A structured critique that generates **new, refined queries** to fill the gaps.\n",
    "\n",
    "Orchestrator: **(Self-Correction Loop)** -> If the Critique Agent finds gaps, the Orchestrator sends the refined queries back to the Research Scout for iteration (repeat search/ critique).\n",
    "* Output structure: Verified, reliable set of retrieved documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53b6ea26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "from agents import Agent, trace, Runner, function_tool, OpenAIChatCompletionsModel\n",
    "from agents.model_settings import ModelSettings\n",
    "from pydantic import BaseModel, Field, conlist\n",
    "import asyncio\n",
    "from typing import Dict\n",
    "import requests\n",
    "import os\n",
    "from datetime import datetime\n",
    "from IPython.display import Markdown, display\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1e3c29",
   "metadata": {},
   "source": [
    "### Get the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8970f09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "\n",
    "# get the API key\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# connect to endpoints (necessary for Google but not OpenAI)\n",
    "GEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "\n",
    "gemini_client = AsyncOpenAI(base_url=GEMINI_BASE_URL, api_key=google_api_key)\n",
    "\n",
    "gemini_model = OpenAIChatCompletionsModel(model=\"gemini-2.0-flash\", openai_client=gemini_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc9cef9",
   "metadata": {},
   "source": [
    "### Mapper Agent: Structured Outputs\n",
    "\n",
    "The **Research crew** built out in this notebook expects a *MapperAgentOutput* object as the intial input so I am including these classes below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20d51ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnowledgeTriplet(BaseModel):\n",
    "    \"\"\"Represents a single relationship (edge) between two concepts (nodes) \n",
    "    extracted directly from the user's input.\"\"\"\n",
    "    \n",
    "    subject: str = Field(description=\"The primary concept or entity (Node) in the relationship.\")\n",
    "    \n",
    "    # Standardized predicates based on input analysis\n",
    "    # Use one of the following: 'IMPLIES', 'ASSUMES', 'INQUIRES', 'FOCUSES_ON'.\n",
    "    predicate: str = Field(description=\"The nature of the relationship (Edge) between the subject and object (e.g., 'IMPLIES', 'ASSUMES', 'INQUIRES').\")\n",
    "    \n",
    "    object: str = Field(description=\"The secondary concept, claim, or assumption (Node) related to the subject.\")\n",
    "    \n",
    "class MapperAgentOutput(BaseModel):\n",
    "    \"\"\"The complete structured output for the Mapper Agent.\"\"\"\n",
    "    \n",
    "    # The list of relationships forms the Draft Knowledge Graph\n",
    "    draft_knowledge_graph: list[KnowledgeTriplet] = Field(\n",
    "        description=\"A list of KnowledgeTriplet objects representing the conceptual map of the user's input only.\"\n",
    "    )\n",
    "    \n",
    "    # The key decision flag for the next stage\n",
    "    research_needed: bool = Field(\n",
    "        description=\"True if the input is a knowledge-based query ('What are the implications of X?') requiring external evidence. \\\n",
    "            False if it is a simple planning query ('How to build Y?').\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97513c59",
   "metadata": {},
   "source": [
    "### Research crew: Structured Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e58c0044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Query Item\n",
    "class SearchQueryItem(BaseModel):\n",
    "    \"\"\"A single, highly specific search query.\"\"\"\n",
    "    \n",
    "    focus_entity: str = Field(\n",
    "        description=\"They key entity or claim this search query is designed to investigate (e.g., 'four-day work week economic viability').\"\n",
    "    )\n",
    "    \n",
    "    query: str = Field(\n",
    "        description=\"The specific keyword or question for the search engine.\"\n",
    "    )\n",
    "    \n",
    "# Research Scout Output\n",
    "class ResearchScoutOutput(BaseModel):\n",
    "    \"\"\"A collection of generated search queries.\"\"\"\n",
    "    \n",
    "    search_queries: list[SearchQueryItem] = Field(\n",
    "        description=\"A list of specific search queries formulated to investigate the concepts and claims from the Draft Knowledge Graph.\"\n",
    "    )\n",
    "    \n",
    "# Critique Agent Outputs\n",
    "class RefinedQuery(BaseModel):\n",
    "    \"\"\"A new or refined query generated to address a gap in the current evidence.\"\"\"\n",
    "    \n",
    "    reason_for_refinement: str = Field(\n",
    "        description=\"Explains why the current evidence is insufficient (e.g., 'Sources were too old', 'Contradictory data found', 'Missing financial data').\"\n",
    "    )\n",
    "    \n",
    "    new_query: str = Field(\n",
    "        description=\"A highly focused, specific query to fill the identified gap.\"\n",
    "    )\n",
    "    \n",
    "class CritiqueAgentOutput(BaseModel):\n",
    "    \"\"\"The structured report on the quality of the current research results.\"\"\"\n",
    "    \n",
    "    gaps_found: bool = Field(\n",
    "        description=\"True if the current raw results are incomplete, contradictory, or lack sufficient factual support. This triggers the self-correction loop.\"\n",
    "    )\n",
    "    \n",
    "    critique_summary: str = Field(\n",
    "        description=\"A brief summary of the overall evidence quality and the primary missing pieces.\"\n",
    "    )\n",
    "    \n",
    "    refined_queries: list[RefinedQuery] = Field(\n",
    "        description=\"A list of new queries to be executed if gaps_found is True.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616617e1",
   "metadata": {},
   "source": [
    "### Research Scout Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b66763bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research Scout Agent\n",
    "SCOUT_AGENT_INSTRUCTIONS = \"\"\"You are the Research Scout for the Conceptual Pathfinder Agent.\n",
    "Your input is a Draft Knowledge Graph (a list of triplets like 'Concept [IMPLIES] Claim) from the Mapper Agent.\n",
    "\n",
    "**Your Goal:** Generate a set of highly specific, factual search queries to gather evidence for the claims and questions flagged in the graph.\n",
    "Do NOT introduce general planning queries.\n",
    "1. **Prioritize:** Focus searches on any Claims or Concepts connected by the 'INQUIRIES' predicate.\n",
    "2. **Output:** Provide a list of SearchQueryItem objects ready for execution.\"\"\"\n",
    "\n",
    "research_scout_agent = Agent(\n",
    "    name=\"Research Scout\",\n",
    "    instructions=SCOUT_AGENT_INSTRUCTIONS,\n",
    "    model=gemini_model,\n",
    "    output_type=ResearchScoutOutput,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690dbece",
   "metadata": {},
   "source": [
    "### Critique Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07cdd62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Critique Agent\n",
    "CRITIQUE_AGENT_INSTRUCTIONS = \"\"\"You are the Critique Agent.\n",
    "Your input is the set of initial claims AND the raw, summarized search results.\n",
    "\n",
    "**Your Goal:** Evaluate the raw search summaries against the original claims for completeness, factual support, and contradiction.\n",
    "1. **Identify Gaps:** Look for contradictions, summaries that are too generic, or claims with zero factual support.\n",
    "2. **Flag Self-Correction:** Set 'gaps_found' to True if the current evidence is unreliable or insufficient to definitively answer the query.\n",
    "3. **Refine Queries:** If gaps are found, generate highly specific 'new_query' items to target the missing information.\"\"\"\n",
    "\n",
    "critique_agent = Agent(\n",
    "    name=\"Critique Agent\",\n",
    "    instructions=CRITIQUE_AGENT_INSTRUCTIONS,\n",
    "    model=gemini_model,\n",
    "    output_type=CritiqueAgentOutput,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4314feef",
   "metadata": {},
   "source": [
    "### Orchestrator and Search Execution Logic with Serper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0915c9",
   "metadata": {},
   "source": [
    "#### Serper web search `@function_tool`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7638b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def serper_search(query: str) -> str:\n",
    "    \"\"\"Peforms a web search using the Serper API and returns a structured string of results\"\"\"\n",
    "    \n",
    "    SERPER_API_KEY = os.getenv(\"SERPER_API_KEY\")\n",
    "    if not SERPER_API_KEY:\n",
    "        return \"Error: Serper API key not found.\"\n",
    "    url = \"https://google.serper.dev/search\"\n",
    "    payload = {\"q\": query}\n",
    "    headers = {\n",
    "        'X-API-KEY': SERPER_API_KEY,\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=payload)\n",
    "        response.raise_for_status() # Raise an exception for bad status codes\n",
    "        \n",
    "        data = response.json()\n",
    "        \n",
    "        # --- Format the results for the Agent ---\n",
    "        # The agent performs better with a concise, text-based summary.\n",
    "        formatted_results = []\n",
    "        \n",
    "        # Prioritize 'organic' (general web) results\n",
    "        if 'organic' in data:\n",
    "            for item in data['organic'][:3]: # Take the top 3 results\n",
    "                formatted_results.append(f\"Title: {item.get('title')}\\nSnippet: {item.get('snippet')}\\nURL: {item.get('link')}\")\n",
    "                \n",
    "        # Also include 'answerBox' or 'knowledgeGraph' for direct answers\n",
    "        elif 'answerBox' in data and data['answerBox'].get('snippet'):\n",
    "            formatted_results.insert(0, f\"Direct Answer: {data['answerBox']['snippet']}\")\n",
    "        elif 'knowledgeGraph' in data and data['knowledgeGraph'].get('snippet'):\n",
    "            formatted_results.insert(0, f\"Direct Answer: {data['knowledgeGraph']['snippet']}\")\n",
    "            \n",
    "        return \"\\n---\\n\".join(formatted_results) if formatted_results else \"No relevant search results found.\"\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Search Error: Failed to connect to Serper API. Details: {e}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5182ec21",
   "metadata": {},
   "source": [
    "#### Search Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30527adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Agent instructions\n",
    "SEARCH_AGENT_INSTRUCTIONS = \"\"\"You are a research assistant. Given a term you search the web for that term and\n",
    "produce a concise summary of the results. The summary should be no more than 200 words.\n",
    "Capture the main points. Write succinctly, no need to have complete sentences or good gramary. \n",
    "This will be consumed by another Agent synthesizing a report, so it's vital that you capture the\n",
    "essence and ignore all the fluff. Do not include any additional commentary other than the summary itself.\n",
    "\"\"\"\n",
    "\n",
    "search_agent = Agent(\n",
    "    name=\"Search Agent\",\n",
    "    instructions=SEARCH_AGENT_INSTRUCTIONS,\n",
    "    tools=[serper_search],\n",
    "    model=gemini_model,\n",
    "    model_settings=ModelSettings(tool_choice=\"required\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21855082",
   "metadata": {},
   "source": [
    "#### Execute single search function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ea55b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def _execute_single_search(item: SearchQueryItem):\n",
    "    \"\"\"Internal helper to execute a single search using the Search Agent.\"\"\"\n",
    "    \n",
    "    input = f\"Search item: {item.query}\\nFocus: {item.focus_entity}\"\n",
    "    result = await Runner.run(search_agent, input)\n",
    "    \n",
    "    # Return the query and the summarized result together for the Critique Agent\n",
    "    return {\n",
    "        \"query\": item.query,\n",
    "        \"focus\": item.focus_entity,\n",
    "        \"summary\": result.final_output # This is the 200 word summary from Search Agent\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad79c150",
   "metadata": {},
   "source": [
    "#### Run the research crew\n",
    "\n",
    "This is where the input from the **Mapper Agent** will be given to the agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a5cc355",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_research_crew(draft_graph_output: MapperAgentOutput) -> list[dict]:\n",
    "    \"\"\"\n",
    "    The Orchestrator function. Manages the self-correction loop.\n",
    "    Input: The structured output from the Mapper Agent.\n",
    "    Output: A verified list of search result summaries.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Inintial Planning (Scout)\n",
    "    scout_plan_result = await Runner.run(research_scout_agent, draft_graph_output.draft_knowledge_graph)\n",
    "    current_queries: list[SearchQueryItem] = scout_plan_result.final_output.search_queries\n",
    "    \n",
    "    MAX_ITERATIONS = 3\n",
    "    final_verified_results = []\n",
    "    \n",
    "    for iteration in range(MAX_ITERATIONS):\n",
    "        print(f\"\\n--- Research Iteration {iteration + 1} ---\")\n",
    "        \n",
    "        # 2. Execute searches concurrently\n",
    "        tasks = [asyncio.create_task(_execute_single_search(q)) for q in current_queries]\n",
    "        raw_results = await asyncio.gather(*tasks)\n",
    "        \n",
    "        # Consolidate results for the Critique Agent's input\n",
    "        results_text = \"\\n\\n\".join([f\"QUERY: {r['query']}\\nSUMMARY: {r['summary']}\" for r in raw_results])\n",
    "        \n",
    "        # The Critique Agent needs the claims and the new results\n",
    "        critique_input = f\"CLAIMS TO VALIDATE: {draft_graph_output.draft_knowledge_graph}\\n\\nCURRENT RAW RESULTS:\\n{results_text}\"\n",
    "        \n",
    "        # 3. Run the Critique Agent\n",
    "        critique_result = await Runner.run(critique_agent, critique_input)\n",
    "        critique_report: CritiqueAgentOutput = critique_result.final_output\n",
    "        \n",
    "        final_verified_results.extend(raw_results) # Add current results to the final list\n",
    "        \n",
    "        # 4. Check for Gaps (Self-Correction Logic)\n",
    "        if not critique_report.gaps_found:\n",
    "            print(\"Critique successful: Evidence verified and sufficient.\")\n",
    "            return final_verified_results\n",
    "        \n",
    "        # If gaps found, prepare for next iteration\n",
    "        print(f\"Critique found gaps. Refining queries for next iteration. Summary: {critique_report.critique_summary}\")\n",
    "        current_queries = [\n",
    "            SearchQueryItem(focus_entity=q.reason_for_refinement, query=q.new_query)\n",
    "            for q in critique_report.refined_queries\n",
    "        ]\n",
    "        \n",
    "        # Fallback if max iteration reached\n",
    "        print(\"\\nWARNING: Max research iterations reached. Returning unverified results.\")\n",
    "        return final_verified_results\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9c5eeb",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3560b96c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18e0c711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prompt (expects external research to be required)\n",
    "external_research_query = \"Is a four-day work week economically viable for all businesses, or does it only succeed in the tech sector?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67535da4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conceptual-pathfinding-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
